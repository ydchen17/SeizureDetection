{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "raw.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wekk-_-6_xcU"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, auc, roc_curve"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHSJlKfASAMT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxc9rqzE_xcX"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gn-AeUg_xcY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cbe984f2-f16c-4332-ae33-a67ec7773063"
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/ydchen17/datasets/main/uci-epileptic-seizure-recognition.csv\n",
        "df = pd.read_csv('uci-epileptic-seizure-recognition.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 7445k  100 7445k    0     0  20.7M      0 --:--:-- --:--:-- --:--:-- 20.7M\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "      <th>x16</th>\n",
              "      <th>x17</th>\n",
              "      <th>x18</th>\n",
              "      <th>x19</th>\n",
              "      <th>x20</th>\n",
              "      <th>x21</th>\n",
              "      <th>x22</th>\n",
              "      <th>x23</th>\n",
              "      <th>x24</th>\n",
              "      <th>x25</th>\n",
              "      <th>x26</th>\n",
              "      <th>x27</th>\n",
              "      <th>x28</th>\n",
              "      <th>x29</th>\n",
              "      <th>x30</th>\n",
              "      <th>x31</th>\n",
              "      <th>x32</th>\n",
              "      <th>x33</th>\n",
              "      <th>x34</th>\n",
              "      <th>x35</th>\n",
              "      <th>x36</th>\n",
              "      <th>x37</th>\n",
              "      <th>x38</th>\n",
              "      <th>x39</th>\n",
              "      <th>x40</th>\n",
              "      <th>...</th>\n",
              "      <th>x140</th>\n",
              "      <th>x141</th>\n",
              "      <th>x142</th>\n",
              "      <th>x143</th>\n",
              "      <th>x144</th>\n",
              "      <th>x145</th>\n",
              "      <th>x146</th>\n",
              "      <th>x147</th>\n",
              "      <th>x148</th>\n",
              "      <th>x149</th>\n",
              "      <th>x150</th>\n",
              "      <th>x151</th>\n",
              "      <th>x152</th>\n",
              "      <th>x153</th>\n",
              "      <th>x154</th>\n",
              "      <th>x155</th>\n",
              "      <th>x156</th>\n",
              "      <th>x157</th>\n",
              "      <th>x158</th>\n",
              "      <th>x159</th>\n",
              "      <th>x160</th>\n",
              "      <th>x161</th>\n",
              "      <th>x162</th>\n",
              "      <th>x163</th>\n",
              "      <th>x164</th>\n",
              "      <th>x165</th>\n",
              "      <th>x166</th>\n",
              "      <th>x167</th>\n",
              "      <th>x168</th>\n",
              "      <th>x169</th>\n",
              "      <th>x170</th>\n",
              "      <th>x171</th>\n",
              "      <th>x172</th>\n",
              "      <th>x173</th>\n",
              "      <th>x174</th>\n",
              "      <th>x175</th>\n",
              "      <th>x176</th>\n",
              "      <th>x177</th>\n",
              "      <th>x178</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>column_a</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X21.V1.791</th>\n",
              "      <td>135</td>\n",
              "      <td>190</td>\n",
              "      <td>229</td>\n",
              "      <td>223</td>\n",
              "      <td>192</td>\n",
              "      <td>125</td>\n",
              "      <td>55</td>\n",
              "      <td>-9</td>\n",
              "      <td>-33</td>\n",
              "      <td>-38</td>\n",
              "      <td>-10</td>\n",
              "      <td>35</td>\n",
              "      <td>64</td>\n",
              "      <td>113</td>\n",
              "      <td>152</td>\n",
              "      <td>164</td>\n",
              "      <td>127</td>\n",
              "      <td>50</td>\n",
              "      <td>-47</td>\n",
              "      <td>-121</td>\n",
              "      <td>-138</td>\n",
              "      <td>-125</td>\n",
              "      <td>-101</td>\n",
              "      <td>-50</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>24</td>\n",
              "      <td>48</td>\n",
              "      <td>64</td>\n",
              "      <td>46</td>\n",
              "      <td>13</td>\n",
              "      <td>-19</td>\n",
              "      <td>-61</td>\n",
              "      <td>-96</td>\n",
              "      <td>-130</td>\n",
              "      <td>-132</td>\n",
              "      <td>-116</td>\n",
              "      <td>-115</td>\n",
              "      <td>-71</td>\n",
              "      <td>-14</td>\n",
              "      <td>...</td>\n",
              "      <td>54</td>\n",
              "      <td>90</td>\n",
              "      <td>111</td>\n",
              "      <td>107</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "      <td>-25</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>-44</td>\n",
              "      <td>-33</td>\n",
              "      <td>-57</td>\n",
              "      <td>-88</td>\n",
              "      <td>-114</td>\n",
              "      <td>-130</td>\n",
              "      <td>-114</td>\n",
              "      <td>-83</td>\n",
              "      <td>-53</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-85</td>\n",
              "      <td>-109</td>\n",
              "      <td>-98</td>\n",
              "      <td>-72</td>\n",
              "      <td>-65</td>\n",
              "      <td>-63</td>\n",
              "      <td>-11</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>-17</td>\n",
              "      <td>-15</td>\n",
              "      <td>-31</td>\n",
              "      <td>-77</td>\n",
              "      <td>-103</td>\n",
              "      <td>-127</td>\n",
              "      <td>-116</td>\n",
              "      <td>-83</td>\n",
              "      <td>-51</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X15.V1.924</th>\n",
              "      <td>386</td>\n",
              "      <td>382</td>\n",
              "      <td>356</td>\n",
              "      <td>331</td>\n",
              "      <td>320</td>\n",
              "      <td>315</td>\n",
              "      <td>307</td>\n",
              "      <td>272</td>\n",
              "      <td>244</td>\n",
              "      <td>232</td>\n",
              "      <td>237</td>\n",
              "      <td>258</td>\n",
              "      <td>212</td>\n",
              "      <td>2</td>\n",
              "      <td>-267</td>\n",
              "      <td>-605</td>\n",
              "      <td>-850</td>\n",
              "      <td>-1001</td>\n",
              "      <td>-1109</td>\n",
              "      <td>-1090</td>\n",
              "      <td>-967</td>\n",
              "      <td>-746</td>\n",
              "      <td>-464</td>\n",
              "      <td>-152</td>\n",
              "      <td>118</td>\n",
              "      <td>318</td>\n",
              "      <td>427</td>\n",
              "      <td>473</td>\n",
              "      <td>485</td>\n",
              "      <td>447</td>\n",
              "      <td>397</td>\n",
              "      <td>339</td>\n",
              "      <td>312</td>\n",
              "      <td>314</td>\n",
              "      <td>326</td>\n",
              "      <td>335</td>\n",
              "      <td>332</td>\n",
              "      <td>324</td>\n",
              "      <td>310</td>\n",
              "      <td>312</td>\n",
              "      <td>...</td>\n",
              "      <td>27</td>\n",
              "      <td>146</td>\n",
              "      <td>229</td>\n",
              "      <td>269</td>\n",
              "      <td>297</td>\n",
              "      <td>307</td>\n",
              "      <td>303</td>\n",
              "      <td>305</td>\n",
              "      <td>306</td>\n",
              "      <td>307</td>\n",
              "      <td>280</td>\n",
              "      <td>231</td>\n",
              "      <td>159</td>\n",
              "      <td>85</td>\n",
              "      <td>51</td>\n",
              "      <td>43</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>89</td>\n",
              "      <td>123</td>\n",
              "      <td>136</td>\n",
              "      <td>127</td>\n",
              "      <td>102</td>\n",
              "      <td>95</td>\n",
              "      <td>105</td>\n",
              "      <td>131</td>\n",
              "      <td>163</td>\n",
              "      <td>168</td>\n",
              "      <td>164</td>\n",
              "      <td>150</td>\n",
              "      <td>146</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>143</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X8.V1.1</th>\n",
              "      <td>-32</td>\n",
              "      <td>-39</td>\n",
              "      <td>-47</td>\n",
              "      <td>-37</td>\n",
              "      <td>-32</td>\n",
              "      <td>-36</td>\n",
              "      <td>-57</td>\n",
              "      <td>-73</td>\n",
              "      <td>-85</td>\n",
              "      <td>-94</td>\n",
              "      <td>-99</td>\n",
              "      <td>-94</td>\n",
              "      <td>-96</td>\n",
              "      <td>-104</td>\n",
              "      <td>-103</td>\n",
              "      <td>-92</td>\n",
              "      <td>-75</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-53</td>\n",
              "      <td>-37</td>\n",
              "      <td>-14</td>\n",
              "      <td>-10</td>\n",
              "      <td>-39</td>\n",
              "      <td>-78</td>\n",
              "      <td>-102</td>\n",
              "      <td>-98</td>\n",
              "      <td>-80</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-35</td>\n",
              "      <td>-39</td>\n",
              "      <td>-32</td>\n",
              "      <td>-13</td>\n",
              "      <td>7</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-82</td>\n",
              "      <td>-107</td>\n",
              "      <td>-126</td>\n",
              "      <td>-124</td>\n",
              "      <td>-108</td>\n",
              "      <td>-84</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-56</td>\n",
              "      <td>-63</td>\n",
              "      <td>-62</td>\n",
              "      <td>-33</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>45</td>\n",
              "      <td>37</td>\n",
              "      <td>48</td>\n",
              "      <td>62</td>\n",
              "      <td>80</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-39</td>\n",
              "      <td>-44</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-48</td>\n",
              "      <td>-42</td>\n",
              "      <td>-6</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "      <td>-12</td>\n",
              "      <td>-30</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-36</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X16.V1.60</th>\n",
              "      <td>-105</td>\n",
              "      <td>-101</td>\n",
              "      <td>-96</td>\n",
              "      <td>-92</td>\n",
              "      <td>-89</td>\n",
              "      <td>-95</td>\n",
              "      <td>-102</td>\n",
              "      <td>-100</td>\n",
              "      <td>-87</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-83</td>\n",
              "      <td>-73</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-58</td>\n",
              "      <td>-59</td>\n",
              "      <td>-64</td>\n",
              "      <td>-79</td>\n",
              "      <td>-84</td>\n",
              "      <td>-97</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-75</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-76</td>\n",
              "      <td>-76</td>\n",
              "      <td>-72</td>\n",
              "      <td>-67</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-67</td>\n",
              "      <td>-68</td>\n",
              "      <td>-69</td>\n",
              "      <td>...</td>\n",
              "      <td>-69</td>\n",
              "      <td>-66</td>\n",
              "      <td>-74</td>\n",
              "      <td>-69</td>\n",
              "      <td>-61</td>\n",
              "      <td>-51</td>\n",
              "      <td>-45</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-58</td>\n",
              "      <td>-64</td>\n",
              "      <td>-78</td>\n",
              "      <td>-80</td>\n",
              "      <td>-90</td>\n",
              "      <td>-87</td>\n",
              "      <td>-83</td>\n",
              "      <td>-78</td>\n",
              "      <td>-64</td>\n",
              "      <td>-38</td>\n",
              "      <td>-22</td>\n",
              "      <td>-29</td>\n",
              "      <td>-42</td>\n",
              "      <td>-51</td>\n",
              "      <td>-68</td>\n",
              "      <td>-71</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-74</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-82</td>\n",
              "      <td>-81</td>\n",
              "      <td>-80</td>\n",
              "      <td>-77</td>\n",
              "      <td>-85</td>\n",
              "      <td>-77</td>\n",
              "      <td>-72</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X20.V1.54</th>\n",
              "      <td>-9</td>\n",
              "      <td>-65</td>\n",
              "      <td>-98</td>\n",
              "      <td>-102</td>\n",
              "      <td>-78</td>\n",
              "      <td>-48</td>\n",
              "      <td>-16</td>\n",
              "      <td>0</td>\n",
              "      <td>-21</td>\n",
              "      <td>-59</td>\n",
              "      <td>-90</td>\n",
              "      <td>-103</td>\n",
              "      <td>-84</td>\n",
              "      <td>-43</td>\n",
              "      <td>-9</td>\n",
              "      <td>3</td>\n",
              "      <td>-21</td>\n",
              "      <td>-60</td>\n",
              "      <td>-96</td>\n",
              "      <td>-103</td>\n",
              "      <td>-75</td>\n",
              "      <td>-29</td>\n",
              "      <td>14</td>\n",
              "      <td>55</td>\n",
              "      <td>78</td>\n",
              "      <td>73</td>\n",
              "      <td>28</td>\n",
              "      <td>-13</td>\n",
              "      <td>-43</td>\n",
              "      <td>-68</td>\n",
              "      <td>-78</td>\n",
              "      <td>-75</td>\n",
              "      <td>-55</td>\n",
              "      <td>-41</td>\n",
              "      <td>-19</td>\n",
              "      <td>-20</td>\n",
              "      <td>-29</td>\n",
              "      <td>-36</td>\n",
              "      <td>-20</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>26</td>\n",
              "      <td>10</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>-8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>63</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-9</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-12</td>\n",
              "      <td>-32</td>\n",
              "      <td>-41</td>\n",
              "      <td>-65</td>\n",
              "      <td>-83</td>\n",
              "      <td>-89</td>\n",
              "      <td>-73</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 179 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             x1   x2   x3   x4   x5   x6  ...  x174  x175  x176  x177  x178  y\n",
              "column_a                                  ...                                 \n",
              "X21.V1.791  135  190  229  223  192  125  ...  -103  -127  -116   -83   -51  4\n",
              "X15.V1.924  386  382  356  331  320  315  ...   157   156   154   143   129  1\n",
              "X8.V1.1     -32  -39  -47  -37  -32  -36  ...   -12   -30   -35   -35   -36  5\n",
              "X16.V1.60  -105 -101  -96  -92  -89  -95  ...   -85   -77   -72   -69   -65  5\n",
              "X20.V1.54    -9  -65  -98 -102  -78  -48  ...   -41   -65   -83   -89   -73  5\n",
              "\n",
              "[5 rows x 179 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSE79jV_xcb"
      },
      "source": [
        "# Normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6LyVukE_xcb"
      },
      "source": [
        "X = df.drop('y' ,axis = 1)\n",
        "y = df['y']\n",
        "\n",
        "SS = StandardScaler()\n",
        "SS.fit(X)\n",
        "SS_X = SS.transform(X)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEOLYwUF_xcc"
      },
      "source": [
        "# model tuning\n",
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLPC5I8P_xcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb98f76-c0a3-4c04-804c-cf433bfb2c19"
      },
      "source": [
        "estimator = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "param_grid = {'C': np.logspace(-2,5,40) }\n",
        "LogGS = GridSearchCV(estimator, param_grid)\n",
        "LogGS.fit(SS_X, y)\n",
        "best_Log = LogGS.best_estimator_\n",
        "best_Log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.07896522868499725, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FheRKiG_xcd"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p41kgRyt_xcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fc9cd3-6596-4506-c324-53a2339e6e4d"
      },
      "source": [
        "estimator = SVC(probability=True)\n",
        "param_grid = {'degree': range(2,8),  'C': np.logspace(-2,5,20)}\n",
        "param_grid = { 'C': np.logspace(-2,4,4)}\n",
        "SvmGS = GridSearchCV(estimator, param_grid)\n",
        "SvmGS.fit(SS_X, y)\n",
        "best_SVM = SvmGS.best_estimator_\n",
        "best_SVM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=100.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaPl-VjW_xce"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbSMOpSa_xce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ee0b41-7ba1-4947-e25a-16729b3ca48d"
      },
      "source": [
        "estimator = KNeighborsClassifier()\n",
        "param_grid = {'n_neighbors': range(2,21)}\n",
        "KNNGS = GridSearchCV(estimator, param_grid)\n",
        "KNNGS.fit(SS_X, y)\n",
        "best_KNN = KNNGS.best_estimator_\n",
        "best_KNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xC2ujAp_xce"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_An9Up_xce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743ee852-5221-4ce8-be8a-db567fd9bb26"
      },
      "source": [
        "SS_X_train, SS_X_test, y_train, y_test = train_test_split(SS_X, y, train_size=0.7)\n",
        "Naive_Bayes = GaussianNB()\n",
        "Naive_Bayes.fit(SS_X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qec3A7iF_xce"
      },
      "source": [
        "## ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhwcWrpI_xcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728cb685-3a2d-4cf2-dc05-f87d64898199"
      },
      "source": [
        "estimator = MLPClassifier(max_iter=1000)\n",
        "param_grid = {'hidden_layer_sizes': [64,128,256,512]}\n",
        "MLPGS = GridSearchCV(estimator, param_grid)\n",
        "MLPGS.fit(SS_X, y)\n",
        "best_MLP = MLPGS.best_estimator_\n",
        "best_MLP"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=512, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aZn_Ns8_xcf"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDwmlEPS_xcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fa38ef-7a5d-4b75-9d9d-27b211922f73"
      },
      "source": [
        "estimator = RandomForestClassifier()\n",
        "param_grid = {'max_depth': range(2,10), 'max_features': range(2,35)}\n",
        "RFGS = GridSearchCV(estimator, param_grid)\n",
        "RFGS.fit(SS_X, y)\n",
        "best_RF = RFGS.best_estimator_\n",
        "best_RF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=9, max_features=33,\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrIIzcUE_xcf"
      },
      "source": [
        "## GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAzt6tLs_xcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2798bb13-7d50-4713-b807-76ccb037116a"
      },
      "source": [
        "estimator = GradientBoostingClassifier()\n",
        "param_grid = {'max_depth': range(2,10), 'max_features': ['auto', 'sqrt', 'log2']}\n",
        "GBGS = GridSearchCV(estimator, param_grid)\n",
        "GBGS.fit(SS_X, y)\n",
        "best_GB = GBGS.best_estimator_\n",
        "best_GB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=9,\n",
              "                           max_features='sqrt', max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofgKu4WQQ-YR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIl07R_v5Kk5"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioWFJLC4QzYa"
      },
      "source": [
        "SS_X_train, SS_X_test, y_train, y_test = train_test_split(SS_X, y, train_size=0.7)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTAkL8GFBdMt"
      },
      "source": [
        "def get_metrics(clf, SS_X, y ):\n",
        "    y_pred = clf.predict(SS_X)\n",
        "    y_proba = clf.predict_proba(SS_X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    recall = recall_score(y, y_pred, average = 'macro')\n",
        "    precision = precision_score(y, y_pred, average = 'macro')\n",
        "    f1 = f1_score(y, y_pred, average = 'macro')\n",
        "\n",
        "    onehot_proba = []\n",
        "    onehot_y = []\n",
        "    for i in range(5):\n",
        "        temp_proba = y_proba[:,i]\n",
        "        temp_y = np.where( y == i+1, 1, 0 )\n",
        "        onehot_proba.append(temp_proba)\n",
        "        onehot_y.append(temp_y)\n",
        "\n",
        "    ravel_onehot_proba = np.array(onehot_proba).ravel()\n",
        "    ravel_onehot_y = np.array(onehot_y).ravel()\n",
        "    fpr,tpr,threshold = roc_curve(ravel_onehot_y, ravel_onehot_proba) \n",
        "    roc_auc = auc(fpr,tpr)\n",
        "    return accuracy, recall, precision, f1, roc_auc\n",
        "\n",
        "SS_X_train, SS_X_test, y_train, y_test = train_test_split(SS_X, y, train_size=0.7)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo41D9MJDU7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946954c1-567d-44ee-eedb-cb623331c2bb"
      },
      "source": [
        "best_Log = LogisticRegression(C=0.07896522868499725, class_weight=None, dual=False,\n",
        "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
        "                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)\n",
        "best_Log.fit(SS_X_train, y_train)\n",
        "get_metrics(best_Log, SS_X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2564474065488264,\n",
              " 0.26023400597760793,\n",
              " 0.2553999113817222,\n",
              " 0.24250944535065172,\n",
              " 0.5560294132341332)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y33f0o6t5jxr",
        "outputId": "b9b9bcf2-5f8c-4361-dfa3-0391f69bce23"
      },
      "source": [
        "best_SVM = SVC(C=100.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "best_SVM.fit(SS_X_train, y_train)\n",
        "get_metrics(best_SVM, SS_X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6879165459287163,\n",
              " 0.6899589872622834,\n",
              " 0.6898910477471585,\n",
              " 0.6887665816785808,\n",
              " 0.9294838170282451)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un82wFgk5kmK",
        "outputId": "91afca82-e037-448f-ae12-15d4c065681c"
      },
      "source": [
        "best_KNN = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
        "                     weights='uniform')\n",
        "best_KNN.fit(SS_X_train, y_train)\n",
        "get_metrics(best_KNN, SS_X_test, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4920312952767314,\n",
              " 0.4900668779359697,\n",
              " 0.5771924999305138,\n",
              " 0.4673123414543422,\n",
              " 0.7366211785126724)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwgIkExzXqKU",
        "outputId": "8492929e-9617-4cdf-90a3-f33859da1891"
      },
      "source": [
        "best_KNN.kneighbors_graph(SS_X)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11500x8049 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 23000 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjTnwlqo5k8p",
        "outputId": "cef88753-6f9c-4fae-8fea-59f57bd9d82f"
      },
      "source": [
        "Naive_Bayes = GaussianNB()\n",
        "Naive_Bayes.fit(SS_X_train, y_train)\n",
        "get_metrics(Naive_Bayes, SS_X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.44537815126050423,\n",
              " 0.44831315349528583,\n",
              " 0.453220230722427,\n",
              " 0.43170735673925337,\n",
              " 0.7754525500484869)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAvo9TCz5lkH",
        "outputId": "8d57b1d3-538f-4a56-8630-1004d539f623"
      },
      "source": [
        "best_MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
        "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "              hidden_layer_sizes=512, learning_rate='constant',\n",
        "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
        "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
        "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
        "              warm_start=False)\n",
        "best_MLP.fit(SS_X_train, y_train)\n",
        "get_metrics(best_MLP, SS_X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6928426543031005,\n",
              " 0.6952370319247613,\n",
              " 0.6971474142662382,\n",
              " 0.6953262000354683,\n",
              " 0.9238804390749796)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8RRPjU25wn0",
        "outputId": "07911d77-d921-4d28-a24b-e400896f032e"
      },
      "source": [
        "best_RF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=9, max_features=33,\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "best_RF.fit(SS_X_train, y_train)\n",
        "get_metrics(best_RF, SS_X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5146334395827297,\n",
              " 0.519364073922123,\n",
              " 0.562250606955479,\n",
              " 0.4744973250301959,\n",
              " 0.8380046360014243)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQmNUMTq51my",
        "outputId": "f6ca394c-bae8-45dc-8541-4a1ac6e2ee74"
      },
      "source": [
        "best_GB = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                           learning_rate=0.1, loss='deviance', max_depth=9,\n",
        "                           max_features='sqrt', max_leaf_nodes=None,\n",
        "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                           min_samples_leaf=1, min_samples_split=2,\n",
        "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                           n_iter_no_change=None, presort='deprecated',\n",
        "                           random_state=None, subsample=1.0, tol=0.0001,\n",
        "                           validation_fraction=0.1, verbose=0,\n",
        "                           warm_start=False)\n",
        "best_GB.fit(SS_X_train, y_train)\n",
        "get_metrics(best_GB, SS_X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.689365401332947,\n",
              " 0.6917160768617677,\n",
              " 0.6928222166247149,\n",
              " 0.691897790750534,\n",
              " 0.9278358122293471)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UczuveyXHOw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}